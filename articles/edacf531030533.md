---
title: "【Knowledge Bases for Amazon Bedrock】矛盾した内容のドキュメントを同期するとどう出力されるのか検証してみた"
emoji: "🧠"
type: "tech"
topics: [aws, ai, 生成ai, bedrock, rag]
published: false
publication_name: "linkedge"
---

## はじめに
お疲れ様です。
おおくまです。

今回は、「【Knowledge Bases for Amazon Bedrock】矛盾した内容のドキュメントを同期するとどう出力されるのか検証してみた」ということで、**Knowledge Bases for Amazon Bedrock**について学習する中で、個人的に気になったことを検証してみました。

少しでも皆様の参考になりますと幸いです。

![](https://storage.googleapis.com/zenn-user-upload/c36ee8d6c472-20240907.png =600x)

## 対象読者
:::message
- **生成AI**について興味がある方
- **Amazon Bedrock**について興味がある方
- **Knowledge Bases for Amazon Bedrock**について興味がある方
:::

## 注意点
:::message alert
- 内容に誤りがある場合があります。
- コメント等で教えていただけると幸甚です。
:::

## Amazon Bedrockとは
**Amazon Bedrock**とは、**AWS**が提供する**生成AIサービス**です。
**Amazon Bedrock**を利用することで、**Anthropic社**の**Claudeシリーズ**や、**Meta社**の**Llamaシリーズ**などの**生成AIモデル**を手軽に**サーバーレス**で使用することができます。

https://aws.amazon.com/jp/bedrock/

:::message
- **生成AIモデル**とは、**生成AI**の脳にあたる部分で、膨大なデータからルールやパターンを学習し、それに基づいた分類や予測を行うために使用される

- **基盤モデル**とは、大量のデータでトレーニングされた汎用的な**モデル**のことで、**基盤モデル**をベースに、**モデル**を微調整して特定のタスクに特化させることができる

- **大規模言語モデル**とは、**LLM**とも呼ばれ、言語ベースの処理を汎用的にこなすモデルのことで、OpenAIのChatGPTやGoogleのBERTなどが有名
:::

## Knowledge Bases for Amazon Bedrockとは
**Knowledge Bases for Amazon Bedrock**とは、**Amazon Bedrock**で提供されているサービスの1つで、**S3**や**Web Crawler**などを**データソース**として同期することで、簡単に**RAGアプリ**を構築することができます。

https://aws.amazon.com/jp/bedrock/knowledge-bases/

:::message
**RAG**とは、**Retrieval-Augmented Generation**の略で、**LLM**が学習していない情報を参照し、回答の精度を向上させる技術のこと
:::

## 検証環境
今回、以下の書籍と記事を参考に**Knowledge Bases for Amazon Bedrock**について学習しました。

https://amzn.asia/d/b8gjIp2

https://qiita.com/minorun365/items/24dfb0ea3afde6ed0a56

<br>

今回の検証した**Knowledge Bases for Amazon Bedrock**は以下のように構成しました。
![](https://storage.googleapis.com/zenn-user-upload/0b5527b98838-20240907.webp =500x)

<br>

**S3**には以下のような文章が書かれている**PDF**を2つ格納しました。
![](https://storage.googleapis.com/zenn-user-upload/8765208ca525-20240907.png =500x)
*株式会社おおくまの2023年の年間売上が1000億円であることを示すPDF①*
![](https://storage.googleapis.com/zenn-user-upload/8ebccf89be5a-20240907.png =500x)
*株式会社おおくまの2023年の年間売上が2000億円であることを示すPDF②*

## 検証

今回、プロンプトは、
**「株式会社おおくまの2023年の年間売上はいくらですか？」**
で、質問しました。

### ドキュメント同期前
ドキュメント同期前の出力結果は以下のようになりました。

![](https://storage.googleapis.com/zenn-user-upload/cd454a80310a-20240907.png =500x)

情報が無いため、出力できない旨が出力されました。

### PDF①のみ同期
PDF①のみ同期した時の出力結果は以下のようになりました。

![](https://storage.googleapis.com/zenn-user-upload/7f5df1f6b010-20240907.png =500x)

PDF①の内容が反映され、1000億円である旨が出力されました。

### PDF②を追加で同期
PDF②を追加で同期した時の出力結果は以下のようになりました。

![](https://storage.googleapis.com/zenn-user-upload/8aecfad52ed3-20240907.png =500x)

PDF①とPDF②で、矛盾した情報が提供されていること、2000億円の情報の方が**スコア**が高いこと、などが出力されました。

その後、複数回、同期や質問を試してみましたが、同じような出力結果でした。
てっきり、質問するたびに、1000億円と2000億円の情報がランダムで出力されるのかと思っていましたが、そうではないようです。

また、今回のパターンでは、2000億円の情報の方が**スコア**が高いようですね。
どうして1000億円よりも2000億円の情報の方が**スコア**が高いのでしょうか。

ここで、私の中で、**スコア**が高くなった要因は以下の2つではないかという仮説が生まれました。

**1.最後に同期した情報が優先される**
**2.ドキュメントの作成日時が新しい方が優先される**

では、まず、1つ目の仮説である「最後に同期した情報が優先される」を検証してみます。

### PDF①をS3から削除し、PDF②のみ同期
PDF①をS3から削除し、PDF②のみ同期した時の出力結果は以下のようになりました。

![](https://storage.googleapis.com/zenn-user-upload/3e9c460c4130-20240907.png =500x)

PDF②の内容が反映され、2000億円である旨が出力されました。

### PDF①を再度同期
PDF①を再度同期した時の出力結果は以下のようになりました。

![](https://storage.googleapis.com/zenn-user-upload/411937850b02-20240907.png =500x)

先ほどとは違い、PDF①を後から同期したのにも関わらず、2000億円の方が**スコア**が高い旨が出力されました。
こうなると、1つ目の仮説である「最後に同期した情報が優先される」は違うようです。

次に、2つ目の仮説である「ドキュメントの作成日時が新しい方が優先される」を検証してみます。

### PDF①を再作成し、再度同期
仮説の2つ目である「ドキュメントの作成日時が新しい方が優先される」を検証するために、PDF①を再作成し、再度同期した時の出力結果は以下のようになりました。

![](https://storage.googleapis.com/zenn-user-upload/2e7261c7c012-20240907.png =500x)

PDF①を再作成したにも関わらず、2000億円の方が**スコア**が高い旨が出力されました。
こうなると、2つ目の仮説である「ドキュメントの作成日時が新しい方が優先される」も違うようです。

## まとめ
今回の検証結果から、**Knowledge Bases for Amazon Bedrock**で構築した**RAGアプリ**は、矛盾した内容のドキュメントを同期すると、矛盾した内容のドキュメントがあること、どの情報が**スコア**が高いかなどを出力してくれることが分かりました。
また、**スコア**には、同期した順番やドキュメントの作成日時が関係していないことも分かりました。
ドキュメントの書き方や質問の仕方などによって、**スコア**の順位が変動する可能性もあると思います。

今回の検証結果が、皆様の参考になれば幸いです。

最後までお読みいただき、ありがとうございました。

## 参考文献

https://amzn.asia/d/b8gjIp2

https://qiita.com/minorun365/items/24dfb0ea3afde6ed0a56

https://speakerdeck.com/minorun365/6yue-ban

https://qiita.com/sakabe/items/5f14999ded1de087c9b5

https://kdl-di.hatenablog.com/entry/2023/05/24/090000
